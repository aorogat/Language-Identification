{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language_Identification_gram_5_Upload.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnwf-X0hbBJ4",
        "colab_type": "text"
      },
      "source": [
        "<h2>1. Document Language Identification Problem</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ3LOH6YnPIn",
        "colab_type": "text"
      },
      "source": [
        "**Run Once:** This cell has the overall code to test. Illustration of the code is in the subsequent sections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5_rldcxnqh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "#Use the comming 2 commands just with Google coLab\n",
        "nltk.download(\"popular\")\n",
        "nltk.download('all-corpora')\n",
        "\n",
        "def languageIdentifier(text):\n",
        "  #Tokenization\n",
        "  words = nltk.word_tokenize(text)\n",
        "  words=[word.lower() for word in words if word.isalpha()] #ignore non alphabtic\n",
        "  \n",
        "  #Text's grams\n",
        "  grams = []\n",
        "  for word in words:\n",
        "    grams.append(grams_5(word))\n",
        "  grams = list(itertools.chain.from_iterable(grams)) #make it a flat list\n",
        "  \n",
        "  #grams' languages\n",
        "  gram_languages = invertedIndex()\n",
        "  gram_langs = []\n",
        "  for gram in grams:\n",
        "    for (g, lans) in gram_languages:\n",
        "      if gram == g:\n",
        "        gram_langs.append((gram, lans))\n",
        "  langs = []\n",
        "  \n",
        "  for (gram, lang) in gram_langs:\n",
        "    langs.append(lang)\n",
        "  langs = list(itertools.chain.from_iterable(langs))\n",
        "  \n",
        "  #Obtain a sorted list of metioned languages based on their frequiences \n",
        "  langsSet = set(langs)\n",
        "  langFreq = []\n",
        "  for l in langsSet:\n",
        "    langFreq.append((l, langs.count(l)))\n",
        "  langFreq = sorted(langFreq, key=lambda tup:(-tup[1], tup[0]))\n",
        "  \n",
        "  return langFreq\n",
        "\n",
        "#Build the inverted index\n",
        "def invertedIndex():\n",
        "  language_grams, noOfGrams = indexing()\n",
        "  \n",
        "  #Unique grams in all languages\n",
        "  all_unique_grams = []\n",
        "  langIds = nltk.corpus.udhr.fileids()\n",
        "  for (id,grams) in language_grams:\n",
        "    for gram in grams:\n",
        "      all_unique_grams.append(gram)\n",
        "  all_unique_grams = set(all_unique_grams)\n",
        "\n",
        "  #Inverted index [(gram,[list of possible languages])]\n",
        "  gram_languages = []\n",
        "  for gram in all_unique_grams:\n",
        "    curr_gram_languages = []\n",
        "    for (cid,grams) in language_grams:\n",
        "      if gram in grams:\n",
        "        curr_gram_languages.append(cid)\n",
        "    gram_languages.append((gram, curr_gram_languages))\n",
        "  return gram_languages\n",
        "\n",
        "#Forward index [(language, [list of possible grams])] i.e 5-grams for all languages\n",
        "def indexing():\n",
        "  langIds = nltk.corpus.udhr.fileids()\n",
        "  language_grams = []\n",
        "  sum = 0\n",
        "  for id in langIds:\n",
        "    lang_grams = language_grams_5(id)\n",
        "    sum = sum + len(lang_grams)\n",
        "    language_grams.append((id,lang_grams))\n",
        "  return language_grams, sum\n",
        "\n",
        "# 5-grams in a specific language\n",
        "import itertools\n",
        "def language_grams_5(languageId):\n",
        "  words = nltk.corpus.udhr.words(languageId)\n",
        "  words=[word.lower() for word in words if word.isalpha()] #ignore non alphabtic\n",
        "  grams = []\n",
        "  for word in words:\n",
        "    grams.append(grams_5(word))\n",
        "  grams = list(itertools.chain.from_iterable(grams)) #make it a flat list\n",
        "  grams = set(grams)\n",
        "  return grams\n",
        "\n",
        "#5-grams in one word\n",
        "def grams_5(word):\n",
        "  grams = []\n",
        "  if len(word) >= 5:\n",
        "    for x in range(len(word)-4):\n",
        "      grams.append(gram_5(word, x))\n",
        "  else:\n",
        "    grams.append(word)\n",
        "  return grams\n",
        "\n",
        "# 5-gram in a word starting from a specfic position i\n",
        "def gram_5(word, i):\n",
        "    firstChar = word[i]\n",
        "    secondChar = word[i+1]\n",
        "    thirdChar = word[i+2]\n",
        "    fourthChar = word[i+3]\n",
        "    fivethChar = word[i+4]\n",
        "    gram = firstChar+secondChar+thirdChar+fourthChar+fivethChar\n",
        "    return gram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNzJl4_-oWz7",
        "colab_type": "code",
        "outputId": "c3845fe5-20f3-4e80-cd15-26e9e12f9a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Test German_Deutsch text\n",
        "language = languageIdentifier('Zu meiner Familie gehören vier Personen. Die Mutter bin ich und dann gehört natürlich mein Mann dazu.' + \n",
        "                              'Wir haben zwei Kinder, einen Sohn, der sechs Jahre alt ist und eine dreijährige Tochter.')\n",
        "print(language[0]) #The number in output indicates the number of grams found in the inverted index."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('German_Deutsch-Latin1', 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLvExmBSbBJ5",
        "colab_type": "text"
      },
      "source": [
        "<h3>Illustration</h3>\n",
        "<p>\n",
        "This problem can be solved as a classification problem. But in this assignments, I solved it as an Information Retrival problem. First, an inverted index from a set of documents in different languages has been built. The nltk's Universal Declaration of Human Rights (udhr) documents in over 300 languages have been used as a data set.\n",
        "</p>\n",
        "<p>\n",
        "    The inverted index will be a data structure for the 5-grams (5 characters) of words and their languages. e.g.<br/>\n",
        "    <pre>\n",
        "    |---------------------------------------------------------------------------------\n",
        "    |5-gram   | Languages    \n",
        "    |---------------------------------------------------------------------------------    \n",
        "    |'butuk'  | ['Bemba-Latin1', 'Kicongo-Latin1', 'Kituba-Latin1', 'Lozi-Latin1' ] \n",
        "    |  ....   |  ...\n",
        "    |'јыўсх'  | ['Belorus_Belaruski-Cyrillic']    \n",
        "    |'tific'  | ['English-Latin1', 'Bemba-Latin1', 'Catalan-Latin1', ..., 'Tetum-Latin1']   \n",
        "    |  ...    |  ...\n",
        "    |--------------------------------------------------------------------------------- \n",
        "\n",
        "Note: Words with characters less than or equal to 5 are treated as 5-grams\n",
        "</pre>\n",
        "\n",
        "    </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzT6f4ppbBJ7",
        "colab_type": "text"
      },
      "source": [
        "<h3>1.1. Data set</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IhLym0dV4yyk",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "#Use the comming 2 commands just with Google coLab\n",
        "nltk.download(\"popular\")\n",
        "nltk.download('all-corpora')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "24Q0ll0G68Gf",
        "outputId": "d216057d-74b7-40f1-c2f6-fd1770bfb35f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Data set ---> udhr: Universal Declaration of Human Rights in over 300 languages\n",
        "langIds = nltk.corpus.udhr.fileids()\n",
        "print(nltk.corpus.udhr.words('English-Latin1')[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Universal', 'Declaration', 'of', 'Human', 'Rights', 'Preamble', 'Whereas', 'recognition', 'of', 'the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd6E8MGybBKG",
        "colab_type": "text"
      },
      "source": [
        "<h3> 1.2. 5_Grams Extraction <h3/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyw1_WOeosJ1",
        "colab_type": "text"
      },
      "source": [
        "In this subsection, we will illustrate how to extract the 5-grams from a given word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xPYDTllQIb-m",
        "colab": {}
      },
      "source": [
        "# 5-gram in a word starting from a specfic position i\n",
        "def gram_5(word, i):\n",
        "    firstChar = word[i]\n",
        "    secondChar = word[i+1]\n",
        "    thirdChar = word[i+2]\n",
        "    fourthChar = word[i+3]\n",
        "    fivethChar = word[i+4]\n",
        "    gram = firstChar+secondChar+thirdChar+fourthChar+fivethChar\n",
        "    return gram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GTdEIlzJNGxy",
        "outputId": "63e77e60-5472-47f9-a962-c452a16419ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Test gram_5 function\n",
        "print(gram_5('hello',0))\n",
        "print(gram_5('Abdelghny',1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n",
            "bdelg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6DQxZVkoIwAT",
        "colab": {}
      },
      "source": [
        "#5-grams in one word\n",
        "def grams_5(word):\n",
        "  grams = []\n",
        "  if len(word) >= 5:\n",
        "    for x in range(len(word)-4):\n",
        "      grams.append(gram_5(word, x))\n",
        "  else:\n",
        "    grams.append(word)\n",
        "  return grams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iv4ZYG7oM3AH",
        "outputId": "f585da56-3654-47f8-d971-a2c655cc33a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Test grams_5 function\n",
        "print(grams_5('Democracy'))\n",
        "print(grams_5('if'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Democ', 'emocr', 'mocra', 'ocrac', 'cracy']\n",
            "['if']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIKkjGvFbBKb",
        "colab_type": "text"
      },
      "source": [
        "<h3>1.3. 5_Grams in our Data Set</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXz-OhuMo7cR",
        "colab_type": "text"
      },
      "source": [
        "In this subsection, we will illustrate how to extract the 5-grams from all words in our data set. We also illustrate how to build the forword index for languages and their grams.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nfUhnViYILyo",
        "colab": {}
      },
      "source": [
        "# 5-grams in a specific language\n",
        "import itertools\n",
        "def language_grams_5(languageId):\n",
        "  words = nltk.corpus.udhr.words(languageId)\n",
        "  words=[word.lower() for word in words if word.isalpha()] #ignore non alphabtic\n",
        "  grams = []\n",
        "  for word in words:\n",
        "    grams.append(grams_5(word))\n",
        "  grams = list(itertools.chain.from_iterable(grams)) #make it a flat list\n",
        "  grams = set(grams)\n",
        "  return grams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SfDFbL8ORveJ",
        "outputId": "665fb0ce-3f70-41a2-8657-34054e777aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Test 5-grams in english\n",
        "english_grams = language_grams_5('English-Latin1')\n",
        "print(len(english_grams))\n",
        "print(list(english_grams)[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1318\n",
            "['spous', 'urces', 'end', 'izati', 'nizat', 'hemse', 'lting', 'avery', 'ivers', 'prove']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3yf95_HeRg62",
        "colab": {}
      },
      "source": [
        "#Forward index [(language, [list of possible grams])] i.e 5-grams for all languages\n",
        "def indexing():\n",
        "  langIds = nltk.corpus.udhr.fileids()\n",
        "  language_grams = []\n",
        "  sum = 0\n",
        "  for id in langIds:\n",
        "    lang_grams = language_grams_5(id)\n",
        "    #print(len(lang_grams))\n",
        "    sum = sum + len(lang_grams)\n",
        "    #print(lang_grams)\n",
        "    language_grams.append((id,lang_grams))\n",
        "  return language_grams, sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNhkeYxoeQKU",
        "colab_type": "code",
        "outputId": "bc1a722c-242c-4aa7-fc91-07e0c828ade4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#Check some languages and their grams\n",
        "language_grams, noOfGrams = indexing()\n",
        "print('Languages and their grams with total ', noOfGrams, ' grams')\n",
        "print('====================================================')\n",
        "count = 0\n",
        "for (l,g) in language_grams:\n",
        "  count = count +1\n",
        "  if count <= 5:\n",
        "    print(l, '\\t', list(g)[:10])\n",
        "print('....')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Languages and their grams with total  348706  grams\n",
            "====================================================\n",
            "Abkhaz-Cyrillic+Abkh \t ['яьшъы', 'хаз', 'иагьы', 'ианил', 'оуран', 'андаю', 'хеидк', 'аёъгь', 'еконо', 'азаро']\n",
            "Abkhaz-UTF8 \t ['яьшъы', 'иагьы', 'ианил', 'оуран', 'андаю', 'аёъгь', 'азаро', 'шъйъы', 'ъылаз', 'мблеи']\n",
            "Achehnese-Latin1 \t ['bak', 'cit', 'apeug', 'eulit', 'unjon', 'dipeu', 'umboi', 'alaik', 'unyat', 'unang']\n",
            "Achuar-Shiwiar-Latin1 \t ['eench', 'tekai', 'kasht', 'mirka', 'mnash', 'jnais', 'chamn', 'ruatn', 'ntimt', 'anúia']\n",
            "Adja-UTF8 \t ['gbaza', 'afɛɖe', 'àcɛ', 'faa', 'unuya', 'mɛnyw', 'kodi', 'anɖeɖ', 'egbɛm', 'aliɖe']\n",
            "....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRu6wduYbBLM",
        "colab_type": "text"
      },
      "source": [
        "<h3>1.5. Inverted Index</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN9T6S5ipUQE",
        "colab_type": "text"
      },
      "source": [
        "In this subsection, we will illustrate how to build the inverted index grams and their languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_gnKlV7GeK6B",
        "colab": {}
      },
      "source": [
        "def invertedIndex():\n",
        "  language_grams, noOfGrams = indexing()\n",
        "  \n",
        "  #Unique grams in all languages\n",
        "  all_unique_grams = []\n",
        "  langIds = nltk.corpus.udhr.fileids()\n",
        "  for (id,grams) in language_grams:\n",
        "    for gram in grams:\n",
        "      all_unique_grams.append(gram)\n",
        "  all_unique_grams = set(all_unique_grams)\n",
        "\n",
        "  #Inverted index [(gram,[list of possible languages])]\n",
        "  gram_languages = []\n",
        "  for gram in all_unique_grams:\n",
        "    curr_gram_languages = []\n",
        "    for (cid,grams) in language_grams:\n",
        "      if gram in grams:\n",
        "        curr_gram_languages.append(cid)\n",
        "    gram_languages.append((gram, curr_gram_languages))\n",
        "  return gram_languages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzvLknM1fGlM",
        "colab_type": "code",
        "outputId": "591d06ab-c979-403a-e282-1e058b018c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "#Print Inverted index\n",
        "gram_languages = invertedIndex()\n",
        "count = 0\n",
        "print('Inverted Index for', len(gram_languages), ' grams')\n",
        "print('================================')\n",
        "print('5-Gram', '\\t', 'Languages')\n",
        "print('-------------------------')\n",
        "for (g,l) in gram_languages:\n",
        "  count = count +1\n",
        "  if count <= 8:\n",
        "    print(g, '\\t', l)\n",
        "print('...', '\\t', '...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inverted Index for 198927  grams\n",
            "================================\n",
            "5-Gram \t Languages\n",
            "-------------------------\n",
            "srugu \t ['Garifuna_Garifuna-Latin1']\n",
            "uchur \t ['Uighur_Uyghur-Latin1', 'Uighur_Uyghur-UTF8', 'Yagua-Latin1']\n",
            "lemal \t ['Cakchiquel-Latin1', 'Kiche_Quiche-Latin1', 'Nyanja_Chinyanja-Latin1', 'Palauan-Latin1', 'Tzeltal-Latin1']\n",
            "nonpi \t ['Chayahuita-Latin1']\n",
            "siigu \t ['Sami_Lappish-UTF8']\n",
            "osame \t ['Slovenian_Slovenscina-Latin2']\n",
            "iena \t ['Huitoto_Murui-Latin1']\n",
            "enles \t ['Uighur_Uyghur-Latin1', 'Uighur_Uyghur-UTF8']\n",
            "... \t ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSs62UK2bBLZ",
        "colab_type": "text"
      },
      "source": [
        "<h3>1.6. Language Identifier</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rbmDWZEpcKk",
        "colab_type": "text"
      },
      "source": [
        "Here, the code used to identify the given text language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wbsBhQWT5CIW",
        "colab": {}
      },
      "source": [
        "def languageIdentifier(text):\n",
        "  #Tokenization\n",
        "  words = nltk.word_tokenize(text)\n",
        "  words=[word.lower() for word in words if word.isalpha()] #ignore non alphabtic\n",
        "  \n",
        "  #print('words: ')\n",
        "  #print(len(words))\n",
        "  #print(words)\n",
        "  \n",
        "  #Text's grams\n",
        "  grams = []\n",
        "  for word in words:\n",
        "    grams.append(grams_5(word))\n",
        "  grams = list(itertools.chain.from_iterable(grams)) #make it a flat list\n",
        "  #grams = set(grams)\n",
        "  \n",
        "  #print('grams: ')\n",
        "  #print(len(grams))\n",
        "  #print(grams)\n",
        "  \n",
        "  #grams' languages\n",
        "  gram_langs = []\n",
        "  for gram in grams:\n",
        "    for (g, lans) in gram_languages:\n",
        "      if gram == g:\n",
        "        gram_langs.append((gram, lans))\n",
        "  langs = []\n",
        "  \n",
        "  #print('gram_langs: ')\n",
        "  #print(len(gram_langs))\n",
        "  #print(gram_langs)\n",
        "  \n",
        "  for (gram, lang) in gram_langs:\n",
        "    langs.append(lang)\n",
        "  langs = list(itertools.chain.from_iterable(langs))\n",
        "  \n",
        "  #Obtain a sorted list of metioned languages based on their frequiences \n",
        "  langsSet = set(langs)\n",
        "  langFreq = []\n",
        "  for l in langsSet:\n",
        "    langFreq.append((l, langs.count(l)))\n",
        "  langFreq = sorted(langFreq, key=lambda tup:(-tup[1], tup[0]))\n",
        "  \n",
        "  return langFreq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR_NMNUsbBLd",
        "colab_type": "text"
      },
      "source": [
        "<h3>1.7. Test</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SB3BbTzxHAT6",
        "outputId": "b1e5b6e6-23bd-4e62-f9ea-a387ee2fef8e",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Test Arabic text\n",
        "language = languageIdentifier('مِصرَ أو (رسمياً: جُمهورِيّةُ مِصرَ العَرَبيّةِ) هي دولة عربية تقع في الركن الشمالي الشرقي من قارة أفريقيا، ولديها امتداد آسيوي، حيث تقع شبه جزيرة سيناء داخل قارة آسيا فهي دولة عابرة للقارات، قُدّر من من عدد سكانها بـ104 مليون نسمة')\n",
        "print(language[0])  #The number in output indicates the number of grams found in the inverted index."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Arabic_Alarabia-Arabic', 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m3wpBTCzyfYM",
        "outputId": "259b409c-2d28-4b76-a29e-2995a0aa5164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Test English text\n",
        "language = languageIdentifier('It is the best book in machine learning')\n",
        "print(language[0]) #The number in output indicates the number of grams found in the inverted index."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('English-Latin1', 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7xWwXUg20662",
        "outputId": "b0a2fa38-414e-42ab-bd51-9813f60f5955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Test Spanish text\n",
        "language = languageIdentifier('Me llamo Elena y estoy profesora de español en una escuela de Salamanca. Soy 29 años y así es un día normal para mí: Yo despierto más temprano, sobre las 6, pero no me levanto hasta las 6:30. Me ducha y me preparo la desayuno. Me visto y voy en la escuela en pie; la gente, en Salamanca, caminan mucho. Termino las clases a las 14 y vuelvo a la mía casa. Por la tarde, estudio y preparo las clases.')\n",
        "print(language[0]) #The number in output indicates the number of grams found in the inverted index."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Spanish-Latin1', 39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tMIo0uaV17Rw",
        "outputId": "fc69200e-cc53-46b9-fbf7-9f03bc4e2f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Test German_Deutsch text\n",
        "language = languageIdentifier('Zu meiner Familie gehören vier Personen. Die Mutter bin ich und dann gehört natürlich mein Mann dazu. Wir haben zwei Kinder, einen Sohn, der sechs Jahre alt ist und eine dreijährige Tochter.')\n",
        "print(language[0]) #The number in output indicates the number of grams found in the inverted index."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('German_Deutsch-Latin1', 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1y0QxrnqnbI_",
        "outputId": "5e81273f-04f8-4ac9-c43a-4ed4fc9c5db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Try it yourself\n",
        "language = languageIdentifier('Write your text here. When text become longer, confidence (grams frequencies here) will be better')\n",
        "print(language[0]) #The number in output indicates the number of grams found in the inverted index."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('English-Latin1', 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmYyG9mVpk7u",
        "colab_type": "text"
      },
      "source": [
        "**Note**: we can enhance our accuracy by choosing a better dataset with more different words.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxsvBREYfT5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
